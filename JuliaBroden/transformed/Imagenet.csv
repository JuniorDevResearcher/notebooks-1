Entity,Year,Imagenet_extra_training_data,Top1_accuracy,Top5_accuracy
Advprop (efficientnet-b8),2019,Without Extra Training Data,0.855,0.973
Alexnet,2012,Without Extra Training Data,0.633,0.846
Alexnet - 7cnns + imagenet 2011 pretrain,2012,With Extra Training Data,0.633,0.846
Bit-l (resnet),2019,With Extra Training Data,0.8754,0.9846
Coatnet-7,2021,With Extra Training Data,0.9088,NA
Efficientnet-l2-475 (sam),2020,With Extra Training Data,0.8861,NA
Five base + five hires,2013,Without Extra Training Data,0.663,NA
Fix-efficientnet-b8 (maxup + cutmix),2020,Without Extra Training Data,0.858,NA
Fixefficientnet-b8,2020,Without Extra Training Data,NA,0.976
Florence-coswim-h,2021,With Extra Training Data,NA,0.9902
Gpipe,2018,Without Extra Training Data,0.844,NA
"Inception resnet v2 + multi-crop, multi-scale",2016,Without Extra Training Data,NA,0.963
Inception v3,2015,Without Extra Training Data,0.788,0.944
Inception v3*,2015,With Extra Training Data,0.788,NA
Jft-300m finetuning,2017,With Extra Training Data,0.792,0.947
"Mae (vit-h, 448)",2021,Without Extra Training Data,0.878,NA
Nasnet-a(6),2017,Without Extra Training Data,NA,0.962
Nfnet-f6 w/ sam,2021,Without Extra Training Data,NA,0.979
Noisystudent (efficientnet-l2),2020,With Extra Training Data,NA,0.987
Overfeat - 7 accurate models,2013,Without Extra Training Data,NA,0.868
Pnasnet-5,2017,Without Extra Training Data,0.829,NA
Resnet-101,2015,With Extra Training Data,NA,0.9395
Resnext-101 32x16d,2018,Without Extra Training Data,NA,0.972
Resnext-101 32x48d,2018,With Extra Training Data,0.854,0.976
Resnext-101 64x4 + multi-scale dense testing,2016,Without Extra Training Data,0.823,NA
Vgg-19,2014,Without Extra Training Data,0.745,0.92
Vgg-19*,2014,With Extra Training Data,0.745,NA
