{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide vs long table format\n",
    "\n",
    "## Summary\n",
    "\n",
    "This was evaluated on WHO indicators dataset with about 30k variables and 16k rows (in wide format).\n",
    "\n",
    "* **Long format & parquet sucks, we should use wide & feather for maximum performance** (or DuckDB instead of feather if loading files from S3 is too slow)\n",
    "\n",
    "* **The most straightfoward solution would be to split the dataset into ~10 tables and save them as wide tables**. Since we'd be indexing them anyway, we could get the path to variables easily. E.g. path would be `dataset_5438/variables_0_to_1000/age_group_years_5_to_17`.\n",
    "\n",
    "* Alternative is to keep it wide and be ok with ~200ms latency (and about 3mins processing time), keeping it in long format in feather format still takes ~200ms!\n",
    "\n",
    "* Querying large dataset would be slow for both feather and parquet formats (long doesn't have indexing and wide takes a long time because there are too many columns)\n",
    "\n",
    "* Indexable DB (MySQL, SQLite) with data stored in long format would be optimal for quering single variable (<10ms performance). Loading data into DuckDB to disk and indexing doesn't help (same performance as loading from feather), we'd have to load it into memory and index it.\n",
    "\n",
    "## Notes\n",
    "\n",
    "There are tradeoffs between storing data in long or wide format. Choosing a format is a prerequisite for choosing the right tool from the solution space.\n",
    "\n",
    "Most of our datasets would benefit from the wide tabular format, but there are some datasets that are almost impossible (or at least impractical) to store in a wide format without post-processing. This happens when data is too sparse (i.e. each variable only contains a few countries and years) when there are a lot of variables. Such an example are WHO indicators with 30k variables (a lot of them are dimensions) where a long format has 45MB while the wide format has almost 2GB uncompressed (with only about 1% non-null values). On the other hand, covid data benefit from wide format since we have data for almost every country & date.\n",
    "\n",
    "### Wide format\n",
    "\n",
    "- Most of our datasets benefit from converting to wide format\n",
    "- Variables can have different types & be stored efficiently in feather file\n",
    "- Querying single variable from a dataset is fast (<10ms unless the dataset has >1000 columns)\n",
    "- Works very poorly for a few datasets\n",
    "\n",
    "### Long format\n",
    "\n",
    "- Universal format, but inefficient storage for most datasets\n",
    "- Same as what we use in MySQL\n",
    "- Fast queries from a database (with index), but queries from feather could be slow if the dataset is large\n",
    "\n",
    "### Split long datasets into multiple tables\n",
    "\n",
    "- Variables from these huge datasets could be grouped into tables to have smaller feather files and more efficient lookups\n",
    "- Grouping can be either manual (very tedious) or automatic (table names wouldn’t make any sense which is not very catalog friendly)... alternatively we would reimplement these datasets in `ETL` (since most of them are from importers)\n",
    "- Need for lookup table to identify to which table & column variable id belongs to\n",
    "\n",
    "### Support both wide & long format\n",
    "\n",
    "- Very efficient querying of most datasets (~10ms), but for instance querying a single variable from WHO indicators (stored in long feather format) could take 200ms anyway\n",
    "- Querying large datasets in long format can be slow if we store it in feather format (as it doesn’t have index), but if we used some kind of database (DuckDB or Clickhouse) then maybe indexing could help a lot\n",
    "- Need to manage both formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports and notebook defaults\n",
    "from nbinit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owid.catalog.utils import underscore\n",
    "from owid.catalog.frames import repack_frame\n",
    "\n",
    "# long format example\n",
    "path = '/Users/mojmir/projects/etl/data/backport/owid/latest/dataset_5438_global_health_observatory__world_health_organization__2021_12/dataset_5438_global_health_observatory__world_health_organization__2021_12.feather'\n",
    "\n",
    "# wide format example\n",
    "# path = '/Users/mojmir/projects/etl/data/backport/owid/latest/dataset_5582_global_carbon_budget__global_carbon_project__v2021/dataset_5582_global_carbon_budget__global_carbon_project__v2021.feather'\n",
    "# path = '/Users/mojmir/projects/etl/data/backport/owid/latest/dataset_5357_world_development_indicators__world_bank__2021_07_30/dataset_5357_world_development_indicators__world_bank__2021_07_30.feather'\n",
    "lf = pd.read_feather(path)\n",
    "\n",
    "# raw data is in long format\n",
    "if 'variable_name' in lf.columns:\n",
    "    lf = lf[['entity_name', 'variable_name', 'year', 'value']]\n",
    "\n",
    "    # `value` is categorical for some reason, use `object` and fix it in repack_frame\n",
    "    lf = lf.astype({'value': object})\n",
    "\n",
    "    # use underscored variable names\n",
    "    lf.variable_name = lf.variable_name.map(underscore)\n",
    "\n",
    "    # convert to wide format\n",
    "    wf = lf.pivot(index=['entity_name', 'year'], columns='variable_name', values='value')\n",
    "\n",
    "    # resetting index and repacking can be very slow - 3 mins on my local\n",
    "    wf = repack_frame(wf.reset_index())\n",
    "\n",
    "# raw data is in wide format\n",
    "else:\n",
    "    wf = lf\n",
    "    lf = wf.melt(id_vars=['entity_name', 'year'], value_vars=wf.columns[2:])\n",
    "    lf = lf.astype({'entity_name': 'category', 'year': 'category', 'variable': 'category'}).rename(columns={'variable': 'variable_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feather and parquet use compression by default!\n",
    "lf.to_feather('data/long.feather')\n",
    "lf.to_parquet('data/long.parquet', index=False)\n",
    "wf.to_feather('data/wide.feather')\n",
    "wf.to_parquet('data/wide.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 454872\n",
      "drwxr-xr-x  6 mojmir  staff   192B Apr 27 10:01 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  9 mojmir  staff   288B Apr 27 11:10 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--  1 mojmir  staff    46M Apr 27 11:39 long.feather\n",
      "-rw-r--r--  1 mojmir  staff    27M Apr 27 11:39 long.parquet\n",
      "-rw-r--r--  1 mojmir  staff    75M Apr 27 11:39 wide.feather\n",
      "-rw-r--r--  1 mojmir  staff    74M Apr 27 11:39 wide.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -alh data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long format shape: (6117600, 4)\n",
      "Wide format shape: (15933, 32100)\n",
      "Long format memory: 423.19 MB\n",
      "Wide format memory: 1834.73 MB\n",
      "Density of wide format: 1.20%\n"
     ]
    }
   ],
   "source": [
    "print(f'Long format shape: {lf.shape}')\n",
    "print(f'Wide format shape: {wf.shape}')\n",
    "print(f'Long format memory: {lf.memory_usage(deep=True).sum() / 1e6:.2f} MB')\n",
    "print(f'Wide format memory: {wf.memory_usage(deep=True).sum() / 1e6:.2f} MB')\n",
    "print(f'Density of wide format: {wf.notnull().sum().sum() / wf.shape[0] / wf.shape[1]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading latency of a single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'indicator__deaths_per_100_000_population__sex__female__age_group__30_49_years__causes__bipolar_disorder'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'indicator__deaths_per_100_000_population__sex__female__age_group__30_49_years__causes__bipolar_disorder'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyarrow.feather as feather\n",
    "import pyarrow.parquet as parquet\n",
    "import duckdb\n",
    "\n",
    "variable = lf.variable_name.sample(1).iloc[0]\n",
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# feather long format\n",
    "t = feather.read_table('data/long.feather')\n",
    "db = duckdb.arrow(t)\n",
    "db.query('t', f\"SELECT * FROM t WHERE variable_name = '{variable}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# feather wide format\n",
    "t = feather.read_table('data/wide.feather', columns=['entity_name', 'year', variable])\n",
    "db = duckdb.arrow(t)\n",
    "db.query('t', f\"SELECT * FROM t WHERE {variable} is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# parquet long format with `filters`\n",
    "t = parquet.read_table('data/long.parquet', filters=[('variable_name', '=', variable)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# parquet long format with duckdb\n",
    "t = parquet.read_table('data/long.parquet')\n",
    "db = duckdb.arrow(t)\n",
    "db.query('t', f\"SELECT * FROM t WHERE variable_name = '{variable}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# parquet wide format\n",
    "t = parquet.read_table('data/wide.parquet', columns=['entity_name', 'year', variable])\n",
    "db = duckdb.arrow(t)\n",
    "db.query('t', f\"SELECT * FROM t WHERE {variable} is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create database on disk, it would be way faster in memory, but we can't afford that\n",
    "conn = duckdb.connect('db.duck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# parquet long format through DuckDB\n",
    "conn.execute(f\"select * from read_parquet('data/long.parquet') where variable_name = '{variable}'\").fetch_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "# parquet wide format with duckdb\n",
    "conn.execute(f\"select entity_name, year, {variable} from read_parquet('data/wide.parquet') where {variable} is not null\").fetch_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">_duckdb_extension.DuckDBPyConnection</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13f418cf0</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95m_duckdb_extension.DuckDBPyConnection\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x13f418cf0\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add long format to DuckDB to allow indexing\n",
    "conn.execute('DROP TABLE long');\n",
    "conn.execute(f\"CREATE TABLE long AS SELECT * FROM read_parquet('data/long.parquet');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "conn.execute(f\"select * from long where variable_name = '{variable}'\").fetch_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">_duckdb_extension.DuckDBPyConnection</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13f418cf0</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95m_duckdb_extension.DuckDBPyConnection\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x13f418cf0\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating index doesn't help\n",
    "conn.execute('CREATE INDEX variable_name_idx ON long (variable_name);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "conn.execute(f\"select * from long where variable_name = '{variable}'\").fetch_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading 30k columns to duckdb takes forever\n",
    "if wf.shape[1] <= 5000:\n",
    "    conn.execute(f\"CREATE TABLE wide AS SELECT * FROM read_parquet('data/wide.parquet');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5 -r1\n",
    "if wf.shape[1] <= 5000:\n",
    "    # parquet wide format with duckdb\n",
    "    conn.execute(f\"select entity_name, year, {variable} from wide where {variable} is not null\").fetch_arrow_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl",
   "language": "python",
   "name": "etl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
